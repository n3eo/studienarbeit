{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import traceback\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import logging\n",
    "import mysql.connector\n",
    "from faker import Faker\n",
    "from base64 import a85encode\n",
    "\n",
    "from python.db_connection import DbConnection as DBC\n",
    "from python.fakeinfgen import fakeInfos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create neccesary instances and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/logs/reqs.log'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-589838af56e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m logging.basicConfig(filename=\"/logs/reqs.log\",\n\u001b[1;32m      3\u001b[0m                     \u001b[0mfilemode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     format=FORMAT)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36mbasicConfig\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1893\u001b[0m                 \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filemode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1895\u001b[0;31m                     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1896\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m                     \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, encoding, delay)\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m             \u001b[0mStreamHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresulting\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \"\"\"\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/logs/reqs.log'"
     ]
    }
   ],
   "source": [
    "FORMAT = '%(asctime)-15s %(clientip)s %(user)-8s %(message)s'\n",
    "logging.basicConfig(filename=\"/logs/reqs.log\",\n",
    "                    filemode='w',\n",
    "                    format=FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbc = DBC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    import time\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()        \n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print('%r  %2.2f ms' % \\\n",
    "                  (method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "    \n",
    "    return timed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenObj(obj):\n",
    "    dictVal = {}\n",
    "    \n",
    "    if isinstance(obj,(dict, list)):\n",
    "        \n",
    "        # add indexes to list for iteration\n",
    "        obj = dict(enumerate(obj)) if isinstance(obj, list) else obj\n",
    "        \n",
    "        # loop over entrys and store them in new dict\n",
    "        for key, val in obj.items():\n",
    "            if isinstance(val,(str, int)):\n",
    "                dictVal[str(key)] = val\n",
    "            \n",
    "            # flatten again of the new value is a dict or list\n",
    "            flattened = flattenObj(val)\n",
    "            for key_new, val_new in flattened.items():\n",
    "                dictVal[f\"{key}_{key_new}\"] = val_new\n",
    "    \n",
    "    return dictVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nestedDictGet(item, *keys):\n",
    "    nextBaseItem = item\n",
    "    for key in keys:        \n",
    "        # test if type is list and get the index\n",
    "        # beforeand check if the given value is a \n",
    "        # integer and a valid position in the dict\n",
    "        if isinstance(nextBaseItem, list):\n",
    "            if str(key).isdigit():\n",
    "                if int(key) < len(nextBaseItem):\n",
    "                    nextBaseItem = nextBaseItem[int(key)]\n",
    "                    continue\n",
    "            # return none if the index ist not valid for the\n",
    "            # list and is a not existend as a key in the dict\n",
    "            elif nextBaseItem.get(key) is None:\n",
    "                return None\n",
    "        \n",
    "        # str and int are the information wanted, directly return it\n",
    "        if isinstance(nextBaseItem,(str,int)):\n",
    "            return nextBaseItem\n",
    "        \n",
    "        # test if the key exists onthe dict\n",
    "        # otherwise returns null\n",
    "        if not nextBaseItem.get(key):\n",
    "            return None\n",
    "        \n",
    "        # as a default get the next nested object based on the key\n",
    "        nextBaseItem = nextBaseItem.get(key)\n",
    "        \n",
    "    return nextBaseItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractListSubject(subjects):\n",
    "    if isinstance(subjects, str):\n",
    "        return subjects\n",
    "\n",
    "    topics = []\n",
    "    if isinstance(subjects, list):\n",
    "        for item in subjects:\n",
    "            flattened = flattenObj(subjects)\n",
    "            topics += extractListSubject(flattened)\n",
    "    \n",
    "    if isinstance(subjects, dict):\n",
    "        for key, val in subjects.items():\n",
    "            if not key.find(\"@authority\") >= 0 and not isinstance(val, dict):\n",
    "                topics += val if isinstance(val,list) and not isinstance(val, dict) else [val] # extractListSubject(val))\n",
    "    \n",
    "    # have every topic only one time by \n",
    "    # first cating to set and then back to list\n",
    "    return list(set(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInformationFromDifferentPaths(flattend, PATHS):\n",
    "    information = None\n",
    "    for path in PATHS:\n",
    "        val = flattend.get(str(path))\n",
    "        if val is not None:\n",
    "            information = val\n",
    "            break\n",
    "    return information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractOneGenre(genre_flattend, GENRE_PATHS= [\"0_#text\", \"#text\"]):\n",
    "    return getInformationFromDifferentPaths(genre_flattend, GENRE_PATHS)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCreator(name_flattend, NAME_PATHS = [\"0_namePart_0\", \"namePart_0\", \"0_namePart\"]):\n",
    "    return getInformationFromDifferentPaths(name_flattend, NAME_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPublisher(publisher_flattend, PUBLISHER_PATHS = [\"publisher_0\", \"publisher_1\"]):\n",
    "    return getInformationFromDifferentPaths(publisher_flattend, PUBLISHER_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDate(date_flattend, DATE_PATHS = [\"dateCreated\", \"dateCreated_0_#text\", \"dateIssued\", \"dateIssued_#text\", \"dateIssued_0_#text\", \"dateIssued_0\"]):\n",
    "    publish_date = getInformationFromDifferentPaths(date_flattend, DATE_PATHS)\n",
    "    \n",
    "    # remove chars because sometimes c (=circa) is included\n",
    "    search = re.search(r'\\d+', str(publish_date))\n",
    "    return search[0] if publish_date and search else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEdition(edition_flattend, EDITION_PATHS = [\"edition\"]):\n",
    "    edition = getInformationFromDifferentPaths(edition_flattend, EDITION_PATHS)\n",
    "    \n",
    "    # remove chars because sometimes c (=circa) is included\n",
    "    search = re.search(r'\\d+', str(edition))\n",
    "    return search[0] if edition and search else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAbstract(abstract_flattend, ABSTRACT_PATHS = [\"#text\", \"0\"]):\n",
    "    return getInformationFromDifferentPaths(abstract_flattend, ABSTRACT_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractURL(location_flattend, LOCATION_PATHS = [\"0_url_1_#text\"]):\n",
    "    return getInformationFromDifferentPaths(location_flattend, LOCATION_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInformation(item):\n",
    "    titleInfo_flattend = flattenObj(nestedDictGet(item, \"titleInfo\"))\n",
    "    \n",
    "    title = titleInfo_flattend.get(\"title\") if titleInfo_flattend.get(\"title\") is not None else titleInfo_flattend.get(\"0_title\")\n",
    "    subtitle = titleInfo_flattend.get(\"subTitle\") if titleInfo_flattend.get(\"subTitle\") is not None else titleInfo_flattend.get(\"0_subTitle\")\n",
    "    \n",
    "    name_flattend = flattenObj(nestedDictGet(item, \"name\"))\n",
    "    creator = creator = extractCreator(name_flattend)\n",
    "        \n",
    "    date_flattend = flattenObj(nestedDictGet(item, \"originInfo\"))\n",
    "    publish_date = extractDate(date_flattend)\n",
    "    \n",
    "    abstract_flattend = flattenObj(nestedDictGet(item, \"abstract\"))\n",
    "    abstract = extractAbstract(abstract_flattend)\n",
    "    \n",
    "    subjects = extractListSubject(nestedDictGet(item, \"subject\"))\n",
    "    \n",
    "    fake = Faker()\n",
    "    Faker.seed(title + str(subjects))\n",
    "\n",
    "    genre_flattend = flattenObj(nestedDictGet(item, \"genre\")) \n",
    "    genre = extractOneGenre(genre_flattend) if genre_flattend != {} else fake.word()\n",
    "    \n",
    "    return title, subtitle, publish_date, abstract, creator, subjects, genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPicture(item):\n",
    "    title, subtitle, publish_date, abstract, creator, subjects, genre = extractInformation(item)\n",
    "    \n",
    "    # only gets small preview\n",
    "    location_flattend = flattenObj(nestedDictGet(item, \"location\"))\n",
    "    url = extractURL(location_flattend)\n",
    "    image_a85 = a85encode(requests.get(url).content) if url else None\n",
    "\n",
    "    fake = Faker()\n",
    "    Faker.seed(title + str(subjects))\n",
    "\n",
    "    val_sorte = {\n",
    "        \"Name\": genre,\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "\n",
    "    creator = creator if creator else fake.name()\n",
    "    val_person = {\n",
    "        \"Vorname\": creator.split(\" \")[0],\n",
    "        \"Name\": creator.split(\" \")[-1],\n",
    "        \"Email\": f\"{creator.split(' ')[0]}@{creator.split(' ')[-1]}.{fake.tld()}\",\n",
    "        \"Geburtsdatum\": fake.date_of_birth()\n",
    "    }\n",
    "\n",
    "    val_maler = {\n",
    "        \"PersonenId\": \"\",\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "\n",
    "    val_nichttextmedien = {\n",
    "        \"Titel\": title,\n",
    "        \"Untertitel\": subtitle,\n",
    "        \"Erscheinungsjahr\": publish_date,\n",
    "        \"Kurzbeschreibung\": abstract if abstract else fake.paragraph(),\n",
    "        \"SorteId\": \"\",\n",
    "        \"Typ\": \"\"\n",
    "    }\n",
    "\n",
    "    val_bild = {\n",
    "        \"NichtTextMedienId\": \"\",\n",
    "        \"Bild\": image_a85,\n",
    "        \"MalerId\": \"\"\n",
    "    }\n",
    "\n",
    "    return val_sorte, val_person, val_maler, val_nichttextmedien, val_bild\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractVideo(item):\n",
    "    title, subtitle, publish_date, abstract, creator, subjects, genre = extractInformation(item)\n",
    "\n",
    "    language_flattend = flattenObj(nestedDictGet(item, \"language\"))\n",
    "    language = language_flattend.get(\"languageTerm_1_#text\")\n",
    "\n",
    "    fake = Faker()\n",
    "    Faker.seed(title+language+str(subjects))\n",
    "\n",
    "    val_sorte = {\n",
    "        \"Name\": genre,\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "\n",
    "    val_nichttextmedien = {\n",
    "        \"Titel\": title,\n",
    "        \"Untertitel\": subtitle,\n",
    "        \"Erscheinungsjahr\": publish_date,\n",
    "        \"Kurzbeschreibung\": abstract if abstract else fake.paragraph(),\n",
    "        \"SorteId\": \"\",\n",
    "        \"Typ\": \"\"\n",
    "    }\n",
    "\n",
    "    val_video = {\n",
    "        \"NichtTextMedienId\": \"\",\n",
    "        \"Sprache\": language\n",
    "    }\n",
    "\n",
    "    return val_sorte, val_nichttextmedien, val_video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBook(item):\n",
    "    title, subtitle, publish_date, abstract, creator, subjects, genre = extractInformation(item)\n",
    "    \n",
    "    language_flattend = flattenObj(nestedDictGet(item, \"language\"))\n",
    "    language = language_flattend.get(\"languageTerm_1_#text\")\n",
    "    \n",
    "    originInfo_flattend = flattenObj(nestedDictGet(item, \"originInfo\"))\n",
    "    edition = extractEdition(originInfo_flattend)\n",
    "    \n",
    "    publisher = extractPublisher(originInfo_flattend)\n",
    "    \n",
    "    # factor 100 to create cent values when dividing again\n",
    "    random.seed(title)\n",
    "    price = random.randint(100, 10000)/100\n",
    "\n",
    "    fake = Faker()\n",
    "    Faker.seed(title+language+str(subjects))\n",
    "\n",
    "    val_verlag = {\n",
    "        \"Kurzname\" : publisher,\n",
    "        \"Name\" : fake.company(),\n",
    "        \"Postleitzahl\" : fake.postalcode(),\n",
    "        \"Strasse\" : fake.street_address(),\n",
    "        \"Internetadresse\" : fake.domain_name(),\n",
    "        \"Beschreibung\" : fake.paragraph()\n",
    "    }\n",
    "\n",
    "    val_schlagwort = [\n",
    "        {   \"Wort\": word if word else fake.word(), \"Beschreibung\": fake.paragraph() } for word in subjects\n",
    "    ]\n",
    "\n",
    "    val_buch = {\n",
    "        \"ISBN\": fake.isbn13().replace(\"-\",\"\"),\n",
    "        \"Titel\": title,\n",
    "        \"Untertitel\": subtitle,\n",
    "        \"VerlagId\": \"\",\n",
    "        \"Erscheinungsjahr\": publish_date,\n",
    "        \"SorteId\": \"\",\n",
    "        \"Kurzbeschreibung\": abstract if abstract else fake.paragraph(),\n",
    "        \"Preis\": str(price),\n",
    "        \"Auflage\": edition,\n",
    "        \"Sprache\": language\n",
    "    }\n",
    "\n",
    "    creator = creator if creator else fake.name()\n",
    "    val_person = {\n",
    "        \"Vorname\": creator.split(\" \")[0],\n",
    "        \"Name\": creator.split(\" \")[-1],\n",
    "        \"Email\": f\"{creator.split(' ')[0]}@{creator.split(' ')[-1]}.{fake.tld()}\",\n",
    "        \"Geburtsdatum\": fake.date_of_birth()\n",
    "    }\n",
    "\n",
    "    val_autor = {\n",
    "        \"PersonenId\": \"\",\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "\n",
    "    val_sorte = {\n",
    "        \"Name\": genre,\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "    \n",
    "    return val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&sort=recordIdentifier&resourceType=text\")\n",
    "# r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&sort=recordIdentifier\")\n",
    "# r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&resourceType=still%20image&limit=250&sort=recordIdentifier\")\n",
    "#r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=mona+lisa&resourceType=still%20image&limit=250&sort=recordIdentifier\")\n",
    "#r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&resourceType=still%20image&limit=250&sort=recordIdentifier\")\n",
    "# r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&resourceType=moving%20image&sort=recordIdentifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "status_code: 200\nlenght: 250\n"
    }
   ],
   "source": [
    "print(\"status_code: \" + str(r.status_code))\n",
    "obj = json.loads(r.text)\n",
    "print(\"lenght: \" + str(len(obj[\"items\"][\"mods\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "text\n'extractBook'  53.32 ms\ntext\n'extractBook'  37.98 ms\ntext\n'extractBook'  39.57 ms\ntext\n'extractBook'  42.81 ms\ntext\n'extractBook'  40.15 ms\ntext\n'extractBook'  42.14 ms\ntext\n'extractBook'  40.73 ms\ntext\n'extractBook'  40.96 ms\ntext\n'extractBook'  44.53 ms\ntext\n'extractBook'  46.28 ms\ntext\n'extractBook'  41.21 ms\ntext\n'extractBook'  42.39 ms\ntext\n'extractBook'  39.84 ms\ntext\n'extractBook'  40.63 ms\ntext\n'extractBook'  43.47 ms\ntext\n'extractBook'  41.75 ms\ntext\n'extractBook'  38.91 ms\ntext\n'extractBook'  44.90 ms\ntext\n'extractBook'  37.12 ms\ntext\n'extractBook'  41.51 ms\ntext\n'extractBook'  44.05 ms\ntext\n'extractBook'  38.24 ms\ntext\n'extractBook'  37.72 ms\ntext\n'extractBook'  38.96 ms\ntext\n'extractBook'  37.35 ms\ntext\n'extractBook'  41.71 ms\ntext\n'extractBook'  39.02 ms\ntext\n'extractBook'  40.00 ms\ntext\n'extractBook'  37.89 ms\ntext\n'extractBook'  38.72 ms\ntext\n'extractBook'  43.22 ms\ntext\n'extractBook'  40.36 ms\ntext\n'extractBook'  44.56 ms\ntext\n'extractBook'  42.50 ms\ntext\n'extractBook'  41.78 ms\ntext\n'extractBook'  45.22 ms\ntext\n'extractBook'  39.91 ms\ntext\n'extractBook'  48.85 ms\ntext\n'extractBook'  55.86 ms\ntext\n'extractBook'  40.09 ms\ntext\n'extractBook'  46.02 ms\ntext\n'extractBook'  42.31 ms\ntext\n'extractBook'  42.97 ms\ntext\n'extractBook'  45.48 ms\ntext\n'extractBook'  38.37 ms\ntext\n'extractBook'  37.86 ms\ntext\n'extractBook'  41.42 ms\ntext\n'extractBook'  58.98 ms\ntext\n'extractBook'  40.73 ms\ntext\n'extractBook'  39.75 ms\ntext\n'extractBook'  44.89 ms\ntext\n'extractBook'  43.50 ms\ntext\n'extractBook'  41.15 ms\ntext\n'extractBook'  37.94 ms\ntext\n'extractBook'  46.34 ms\ntext\n'extractBook'  39.42 ms\ntext\n'extractBook'  48.43 ms\ntext\n'extractBook'  43.38 ms\ntext\n'extractBook'  36.78 ms\ntext\n'extractBook'  44.35 ms\ntext\n'extractBook'  40.56 ms\ntext\n'extractBook'  49.29 ms\ntext\n'extractBook'  40.84 ms\ntext\n'extractBook'  40.95 ms\ntext\n'extractBook'  40.45 ms\ntext\n'extractBook'  40.22 ms\ntext\n'extractBook'  37.56 ms\ntext\n'extractBook'  40.81 ms\ntext\n'extractBook'  39.14 ms\ntext\n'extractBook'  49.80 ms\ntext\n'extractBook'  43.67 ms\ntext\n'extractBook'  41.41 ms\ntext\n'extractBook'  37.87 ms\ntext\n'extractBook'  42.16 ms\ntext\n'extractBook'  44.01 ms\ntext\n'extractBook'  39.06 ms\ntext\n'extractBook'  40.26 ms\ntext\n'extractBook'  40.51 ms\ntext\n'extractBook'  40.18 ms\ntext\n'extractBook'  47.31 ms\ntext\n'extractBook'  43.05 ms\ntext\n'extractBook'  37.01 ms\ntext\n'extractBook'  40.46 ms\ntext\n'extractBook'  41.50 ms\ntext\n'extractBook'  51.94 ms\ntext\n'extractBook'  50.55 ms\ntext\n'extractBook'  53.96 ms\ntext\n'extractBook'  45.08 ms\ntext\n'extractBook'  42.21 ms\ntext\n'extractBook'  38.56 ms\ntext\n'extractBook'  40.12 ms\ntext\n'extractBook'  47.19 ms\ntext\n'extractBook'  39.90 ms\ntext\n'extractBook'  45.07 ms\ntext\n'extractBook'  41.73 ms\ntext\n'extractBook'  40.34 ms\ntext\n'extractBook'  41.45 ms\ntext\n'extractBook'  38.31 ms\ntext\n'extractBook'  38.87 ms\ntext\n'extractBook'  40.19 ms\ntext\n'extractBook'  41.24 ms\ntext\n'extractBook'  41.55 ms\ntext\n'extractBook'  40.76 ms\ntext\n'extractBook'  38.55 ms\ntext\n'extractBook'  42.14 ms\ntext\n'extractBook'  42.73 ms\ntext\n'extractBook'  37.86 ms\ntext\n'extractBook'  39.33 ms\ntext\n'extractBook'  39.17 ms\ntext\n'extractBook'  44.08 ms\ntext\n'extractBook'  37.11 ms\ntext\n'extractBook'  38.11 ms\ntext\n'extractBook'  37.17 ms\ntext\n'extractBook'  41.53 ms\ntext\n'extractBook'  40.00 ms\ntext\n'extractBook'  41.42 ms\ntext\n'extractBook'  40.76 ms\ntext\n'extractBook'  43.67 ms\ntext\n'extractBook'  41.86 ms\ntext\n'extractBook'  37.72 ms\ntext\n'extractBook'  38.78 ms\ntext\n'extractBook'  39.81 ms\ntext\n'extractBook'  38.82 ms\ntext\n'extractBook'  36.43 ms\ntext\n'extractBook'  39.26 ms\ntext\n'extractBook'  41.63 ms\ntext\n'extractBook'  36.74 ms\ntext\n'extractBook'  39.13 ms\ntext\n'extractBook'  46.01 ms\ntext\n'extractBook'  37.01 ms\ntext\n'extractBook'  39.44 ms\ntext\n'extractBook'  43.92 ms\ntext\n'extractBook'  36.89 ms\ntext\n'extractBook'  43.54 ms\ntext\n'extractBook'  37.62 ms\ntext\n'extractBook'  37.82 ms\ntext\n'extractBook'  40.12 ms\ntext\n'extractBook'  40.84 ms\ntext\n'extractBook'  38.08 ms\ntext\n'extractBook'  46.52 ms\ntext\n'extractBook'  38.26 ms\ntext\n'extractBook'  41.03 ms\ntext\n'extractBook'  40.03 ms\ntext\n'extractBook'  39.78 ms\ntext\n'extractBook'  36.73 ms\ntext\n'extractBook'  38.23 ms\ntext\n'extractBook'  38.53 ms\ntext\n'extractBook'  41.92 ms\ntext\n'extractBook'  44.21 ms\ntext\n'extractBook'  39.38 ms\ntext\n'extractBook'  41.75 ms\ntext\n'extractBook'  45.40 ms\ntext\n'extractBook'  37.21 ms\ntext\n'extractBook'  45.78 ms\ntext\n'extractBook'  37.52 ms\ntext\n'extractBook'  40.77 ms\ntext\n'extractBook'  38.07 ms\ntext\n'extractBook'  39.09 ms\ntext\n'extractBook'  42.70 ms\ntext\n'extractBook'  39.26 ms\ntext\n'extractBook'  48.33 ms\ntext\n'extractBook'  38.17 ms\ntext\n'extractBook'  37.20 ms\ntext\n'extractBook'  37.83 ms\ntext\n'extractBook'  38.44 ms\ntext\n'extractBook'  45.88 ms\ntext\n'extractBook'  40.68 ms\ntext\n'extractBook'  47.44 ms\ntext\n'extractBook'  42.20 ms\ntext\n'extractBook'  43.93 ms\ntext\n'extractBook'  40.58 ms\ntext\n'extractBook'  38.73 ms\ntext\n'extractBook'  39.28 ms\ntext\n'extractBook'  44.21 ms\ntext\n'extractBook'  39.25 ms\ntext\n'extractBook'  40.38 ms\ntext\n'extractBook'  39.76 ms\ntext\n'extractBook'  44.96 ms\ntext\n'extractBook'  38.96 ms\ntext\n'extractBook'  39.74 ms\ntext\n'extractBook'  41.45 ms\ntext\n'extractBook'  39.53 ms\ntext\n'extractBook'  37.25 ms\ntext\n'extractBook'  40.40 ms\ntext\n'extractBook'  44.77 ms\ntext\n'extractBook'  39.38 ms\ntext\n'extractBook'  39.32 ms\ntext\n'extractBook'  39.13 ms\ntext\n'extractBook'  39.27 ms\ntext\n'extractBook'  39.93 ms\ntext\n'extractBook'  40.12 ms\ntext\n'extractBook'  42.70 ms\ntext\n'extractBook'  38.88 ms\ntext\n'extractBook'  40.95 ms\ntext\n'extractBook'  36.80 ms\ntext\n'extractBook'  37.12 ms\ntext\n'extractBook'  38.10 ms\ntext\n'extractBook'  39.51 ms\ntext\n'extractBook'  39.74 ms\ntext\n'extractBook'  40.31 ms\ntext\n'extractBook'  40.32 ms\ntext\n'extractBook'  41.76 ms\ntext\n'extractBook'  44.94 ms\ntext\n'extractBook'  42.77 ms\ntext\n'extractBook'  39.68 ms\ntext\n'extractBook'  38.68 ms\ntext\n'extractBook'  38.12 ms\ntext\n'extractBook'  37.92 ms\ntext\n'extractBook'  38.56 ms\ntext\n'extractBook'  40.42 ms\ntext\n'extractBook'  39.06 ms\ntext\n'extractBook'  39.04 ms\ntext\n'extractBook'  40.46 ms\ntext\n'extractBook'  39.40 ms\ntext\n'extractBook'  38.78 ms\ntext\n'extractBook'  40.69 ms\ntext\n'extractBook'  37.73 ms\ntext\n'extractBook'  39.16 ms\ntext\n'extractBook'  42.70 ms\ntext\n'extractBook'  40.00 ms\ntext\n'extractBook'  38.83 ms\ntext\n'extractBook'  41.65 ms\ntext\n'extractBook'  37.84 ms\ntext\n'extractBook'  40.99 ms\ntext\n'extractBook'  43.46 ms\ntext\n'extractBook'  41.35 ms\ntext\n'extractBook'  42.14 ms\ntext\n'extractBook'  38.24 ms\ntext\n'extractBook'  39.49 ms\ntext\n'extractBook'  39.29 ms\ntext\n'extractBook'  36.79 ms\ntext\n'extractBook'  40.53 ms\ntext\n'extractBook'  41.88 ms\ntext\n'extractBook'  44.41 ms\ntext\n'extractBook'  37.34 ms\ntext\n'extractBook'  53.98 ms\ntext\n'extractBook'  42.24 ms\ntext\n'extractBook'  40.37 ms\ntext\n'extractBook'  36.65 ms\ntext\n'extractBook'  41.11 ms\ntext\n'extractBook'  39.64 ms\ntext\n'extractBook'  36.58 ms\ntext\n'extractBook'  41.54 ms\ntext\n'extractBook'  40.33 ms\ntext\n'extractBook'  45.05 ms\ntext\n'extractBook'  41.92 ms\ntext\n'extractBook'  45.16 ms\ntext\n'extractBook'  37.56 ms\ntext\n'extractBook'  43.58 ms\ntext\n'extractBook'  38.26 ms\n"
    }
   ],
   "source": [
    "for num, item in enumerate(obj[\"items\"][\"mods\"]):\n",
    "    try:\n",
    "        if item[\"typeOfResource\"] == \"text\":\n",
    "            val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte = extractBook(item)\n",
    "            dbc.insert_book(val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte)\n",
    "        elif item[\"typeOfResource\"] == \"moving image\":\n",
    "            val_sorte, val_nichttextmedien, val_video = extractVideo(item)\n",
    "            dbc.insert_video(val_sorte, val_nichttextmedien, val_video)\n",
    "        else:\n",
    "            val_sorte, val_person, val_maler, val_nichttextmedien, val_bild = extractPicture(item)\n",
    "            dbc.insert_bild(val_sorte, val_person, val_maler, val_nichttextmedien, val_bild)\n",
    "    except Exception as e:\n",
    "        logging.error(traceback.print_exc())\n",
    "        logging.warning(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Call (no functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9500\n",
      "9750\n",
      "10000\n",
      "10250\n",
      "10500\n",
      "10750\n",
      "11000\n",
      "11250\n",
      "11500\n",
      "11750\n",
      "12000\n",
      "12250\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&sort=recordIdentifier\")\n",
    "obj = json.loads(r.text)\n",
    "\n",
    "# obj.get(\"pagination\").get(\"numFound\") exists always\n",
    "for start_value in range( obj.get(\"pagination\").get(\"numFound\") // 250 + 1):\n",
    "    print(f\"{(start_value+1)*250}\")\n",
    "    \n",
    "    r = requests.get(f\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&start={start_value*250}&sort=recordIdentifier\")\n",
    "    obj = json.loads(r.text)\n",
    "    \n",
    "   for item in obj[\"items\"][\"mods\"]:\n",
    "    try:\n",
    "        if item[\"typeOfResource\"] == \"text\":\n",
    "            val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte = extractBook(item)\n",
    "            dbc.insert_book(val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte)\n",
    "        elif item[\"typeOfResource\"] == \"moving image\":\n",
    "            val_sorte, val_nichttextmedien, val_video = extractVideo(item)\n",
    "            dbc.insert_video(val_sorte, val_nichttextmedien, val_video)\n",
    "        else:\n",
    "            val_sorte, val_person, val_maler, val_nichttextmedien, val_bild = extractPicture(item)\n",
    "            dbc.insert_bild(val_sorte, val_person, val_maler, val_nichttextmedien, val_bild)\n",
    "    except Exception as e:\n",
    "        logging.error(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}