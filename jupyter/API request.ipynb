{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Requirement already satisfied: mysql-connector-python in /opt/conda/lib/python3.7/site-packages (8.0.19)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (2.23.0)\nRequirement already satisfied: faker in /opt/conda/lib/python3.7/site-packages (4.0.2)\nRequirement already satisfied: dnspython==1.16.0 in /opt/conda/lib/python3.7/site-packages (from mysql-connector-python) (1.16.0)\nRequirement already satisfied: protobuf==3.6.1 in /opt/conda/lib/python3.7/site-packages (from mysql-connector-python) (3.6.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests) (2019.11.28)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests) (1.25.7)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests) (2.9)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests) (3.0.4)\nRequirement already satisfied: text-unidecode==1.3 in /opt/conda/lib/python3.7/site-packages (from faker) (1.3)\nRequirement already satisfied: python-dateutil>=2.4 in /opt/conda/lib/python3.7/site-packages (from faker) (2.8.1)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf==3.6.1->mysql-connector-python) (46.0.0.post20200311)\nRequirement already satisfied: six>=1.9 in /opt/conda/lib/python3.7/site-packages (from protobuf==3.6.1->mysql-connector-python) (1.14.0)\n"
    }
   ],
   "source": [
    "!pip install mysql-connector-python requests faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import traceback\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import logging\n",
    "import mysql.connector\n",
    "from faker import Faker\n",
    "from base64 import a85encode\n",
    "\n",
    "from python.db_connection import DbConnection as DBC\n",
    "from python.fakeinfgen import fakeInfos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create neccesary instances and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake = Faker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"/jupyter/logs/api_requests.log\",\n",
    "                            filemode='a',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbc = DBC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(method):\n",
    "    import time\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()        \n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print('%r  %2.2f ms' % \\\n",
    "                  (method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "    \n",
    "    return timed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattenObj(obj):\n",
    "    dictVal = {}\n",
    "    \n",
    "    if isinstance(obj,(dict, list)):\n",
    "        \n",
    "        # add indexes to list for iteration\n",
    "        obj = dict(enumerate(obj)) if isinstance(obj, list) else obj\n",
    "        \n",
    "        # loop over entrys and store them in new dict\n",
    "        for key, val in obj.items():\n",
    "            if isinstance(val,(str, int)):\n",
    "                dictVal[str(key)] = val\n",
    "            \n",
    "            # flatten again of the new value is a dict or list\n",
    "            flattened = flattenObj(val)\n",
    "            for key_new, val_new in flattened.items():\n",
    "                dictVal[f\"{key}_{key_new}\"] = val_new\n",
    "    \n",
    "    return dictVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nestedDictGet(item, *keys):\n",
    "    nextBaseItem = item\n",
    "    for key in keys:        \n",
    "        # test if type is list and get the index\n",
    "        # beforeand check if the given value is a \n",
    "        # integer and a valid position in the dict\n",
    "        if isinstance(nextBaseItem, list):\n",
    "            if str(key).isdigit():\n",
    "                if int(key) < len(nextBaseItem):\n",
    "                    nextBaseItem = nextBaseItem[int(key)]\n",
    "                    continue\n",
    "            # return none if the index ist not valid for the\n",
    "            # list and is a not existend as a key in the dict\n",
    "            elif nextBaseItem.get(key) is None:\n",
    "                return None\n",
    "        \n",
    "        # str and int are the information wanted, directly return it\n",
    "        if isinstance(nextBaseItem,(str,int)):\n",
    "            return nextBaseItem\n",
    "        \n",
    "        # test if the key exists onthe dict\n",
    "        # otherwise returns null\n",
    "        if not nextBaseItem.get(key):\n",
    "            return None\n",
    "        \n",
    "        # as a default get the next nested object based on the key\n",
    "        nextBaseItem = nextBaseItem.get(key)\n",
    "        \n",
    "    return nextBaseItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractListSubject(subjects):\n",
    "    if isinstance(subjects, str):\n",
    "        return subjects\n",
    "\n",
    "    topics = []\n",
    "    if isinstance(subjects, list):\n",
    "        for item in subjects:\n",
    "            flattened = flattenObj(item)\n",
    "            topics += extractListSubject(flattened)\n",
    "    \n",
    "    if isinstance(subjects, dict):\n",
    "        for key, val in subjects.items():\n",
    "            if not key.find(\"@authority\") >= 0 and not isinstance(val, dict):\n",
    "                topics += val if isinstance(val,list) and not isinstance(val, dict) else [val] # extractListSubject(val))\n",
    "    \n",
    "    # have every topic only one time by \n",
    "    # first cating to set and then back to list\n",
    "    return list(set(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInformationFromDifferentPaths(flattend, PATHS):\n",
    "    information = None\n",
    "    for path in PATHS:\n",
    "        val = flattend.get(str(path))\n",
    "        if val is not None:\n",
    "            information = val\n",
    "            break\n",
    "    return information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractOneGenre(genre_flattend, GENRE_PATHS= [\"0_#text\", \"#text\"]):\n",
    "    return getInformationFromDifferentPaths(genre_flattend, GENRE_PATHS)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractCreator(name_flattend, NAME_PATHS = [\"0_namePart_0\", \"namePart_0\", \"0_namePart\"]):\n",
    "    return getInformationFromDifferentPaths(name_flattend, NAME_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPublisher(publisher_flattend, PUBLISHER_PATHS = [\"publisher_0\", \"publisher_1\"]):\n",
    "    return getInformationFromDifferentPaths(publisher_flattend, PUBLISHER_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDate(date_flattend, DATE_PATHS = [\"dateCreated\", \"dateCreated_0_#text\", \"dateIssued\", \"dateIssued_#text\", \"dateIssued_0_#text\", \"dateIssued_0\"]):\n",
    "    publish_date = getInformationFromDifferentPaths(date_flattend, DATE_PATHS)\n",
    "    \n",
    "    # remove chars because sometimes c (=circa) is included\n",
    "    search = re.search(r'\\d+', str(publish_date))\n",
    "    return search[0] if publish_date and search else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEdition(edition_flattend, EDITION_PATHS = [\"edition\"]):\n",
    "    edition = getInformationFromDifferentPaths(edition_flattend, EDITION_PATHS)\n",
    "    \n",
    "    # remove chars because sometimes c (=circa) is included\n",
    "    search = re.search(r'\\d+', str(edition))\n",
    "    return search[0] if edition and search else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAbstract(abstract_flattend, ABSTRACT_PATHS = [\"#text\", \"0\"]):\n",
    "    return getInformationFromDifferentPaths(abstract_flattend, ABSTRACT_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractURL(location_flattend, LOCATION_PATHS = [\"0_url_1_#text\"]):\n",
    "    return getInformationFromDifferentPaths(location_flattend, LOCATION_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInformation(item):\n",
    "    titleInfo_flattend = flattenObj(nestedDictGet(item, \"titleInfo\"))\n",
    "    \n",
    "    title = titleInfo_flattend.get(\"title\") if titleInfo_flattend.get(\"title\") is not None else titleInfo_flattend.get(\"0_title\")\n",
    "    subtitle = titleInfo_flattend.get(\"subTitle\") if titleInfo_flattend.get(\"subTitle\") is not None else titleInfo_flattend.get(\"0_subTitle\")\n",
    "    \n",
    "    name_flattend = flattenObj(nestedDictGet(item, \"name\"))\n",
    "    creator = creator = extractCreator(name_flattend)\n",
    "        \n",
    "    date_flattend = flattenObj(nestedDictGet(item, \"originInfo\"))\n",
    "    publish_date = extractDate(date_flattend)\n",
    "    \n",
    "    abstract_flattend = flattenObj(nestedDictGet(item, \"abstract\"))\n",
    "    abstract = extractAbstract(abstract_flattend)\n",
    "    \n",
    "    subjects = extractListSubject(nestedDictGet(item, \"subject\"))\n",
    "    \n",
    "    fake = Faker()\n",
    "    Faker.seed(title + str(subjects))\n",
    "\n",
    "    genre_flattend = flattenObj(nestedDictGet(item, \"genre\")) \n",
    "    genre = extractOneGenre(genre_flattend) if genre_flattend != {} else fake.word()\n",
    "    \n",
    "    return title, subtitle, publish_date, abstract, creator, subjects, genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPicture(item):\n",
    "    title, subtitle, publish_date, abstract, creator, subjects, genre = extractInformation(item)\n",
    "    \n",
    "    # only gets small preview\n",
    "    location_flattend = flattenObj(nestedDictGet(item, \"location\"))\n",
    "    url = extractURL(location_flattend)\n",
    "    image_a85 = a85encode(requests.get(url).content) if url else None\n",
    "\n",
    "    fake = Faker()\n",
    "    Faker.seed(title + str(subjects))\n",
    "\n",
    "    val_sorte = {\n",
    "        \"Name\": genre,\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "\n",
    "    creator = creator if creator else fake.name()\n",
    "    val_person = {\n",
    "        \"Vorname\": creator.split(\" \")[0],\n",
    "        \"Name\": creator.split(\" \")[-1],\n",
    "        \"Email\": f\"{creator.split(' ')[0]}@{creator.split(' ')[-1]}.{fake.tld()}\",\n",
    "        \"Geburtsdatum\": fake.date_of_birth()\n",
    "    }\n",
    "\n",
    "    val_maler = {\n",
    "        \"PersonenId\": \"\",\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "\n",
    "    val_nichttextmedien = {\n",
    "        \"Titel\": title,\n",
    "        \"Untertitel\": subtitle,\n",
    "        \"Erscheinungsjahr\": publish_date,\n",
    "        \"Kurzbeschreibung\": abstract if abstract else fake.paragraph(),\n",
    "        \"SorteId\": \"\",\n",
    "        \"Typ\": \"\"\n",
    "    }\n",
    "\n",
    "    val_bild = {\n",
    "        \"NichtTextMedienId\": \"\",\n",
    "        \"Bild\": image_a85,\n",
    "        \"MalerId\": \"\"\n",
    "    }\n",
    "\n",
    "    return val_sorte, val_person, val_maler, val_nichttextmedien, val_bild\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractVideo(item):\n",
    "    title, subtitle, publish_date, abstract, creator, subjects, genre = extractInformation(item)\n",
    "\n",
    "    language_flattend = flattenObj(nestedDictGet(item, \"language\"))\n",
    "    language = language_flattend.get(\"languageTerm_1_#text\")\n",
    "\n",
    "    fake = Faker()\n",
    "    Faker.seed(title+language+str(subjects))\n",
    "\n",
    "    val_sorte = {\n",
    "        \"Name\": genre,\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "\n",
    "    val_nichttextmedien = {\n",
    "        \"Titel\": title,\n",
    "        \"Untertitel\": subtitle,\n",
    "        \"Erscheinungsjahr\": publish_date,\n",
    "        \"Kurzbeschreibung\": abstract if abstract else fake.paragraph(),\n",
    "        \"SorteId\": \"\",\n",
    "        \"Typ\": \"\"\n",
    "    }\n",
    "\n",
    "    val_video = {\n",
    "        \"NichtTextMedienId\": \"\",\n",
    "        \"Sprache\": language\n",
    "    }\n",
    "\n",
    "    return val_sorte, val_nichttextmedien, val_video\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBook(item):\n",
    "    title, subtitle, publish_date, abstract, creator, subjects, genre = extractInformation(item)\n",
    "    \n",
    "    language_flattend = flattenObj(nestedDictGet(item, \"language\"))\n",
    "    language = language_flattend.get(\"languageTerm_1_#text\")\n",
    "    \n",
    "    originInfo_flattend = flattenObj(nestedDictGet(item, \"originInfo\"))\n",
    "    edition = extractEdition(originInfo_flattend)\n",
    "    \n",
    "    publisher = extractPublisher(originInfo_flattend)\n",
    "    \n",
    "    # factor 100 to create cent values when dividing again\n",
    "    random.seed(title)\n",
    "    price = random.randint(100, 10000)/100\n",
    "\n",
    "    fake = Faker()\n",
    "    Faker.seed(title+language+str(subjects))\n",
    "\n",
    "    val_verlag = {\n",
    "        \"Kurzname\" : publisher,\n",
    "        \"Name\" : fake.company(),\n",
    "        \"Postleitzahl\" : fake.postalcode(),\n",
    "        \"Strasse\" : fake.street_address(),\n",
    "        \"Internetadresse\" : fake.domain_name(),\n",
    "        \"Beschreibung\" : fake.paragraph()\n",
    "    }\n",
    "\n",
    "    val_schlagwort = [\n",
    "        {   \"Wort\": word if word else fake.word(), \"Beschreibung\": fake.paragraph() } for word in subjects\n",
    "    ]\n",
    "\n",
    "    val_buch = {\n",
    "        \"ISBN\": fake.isbn13().replace(\"-\",\"\"),\n",
    "        \"Titel\": title,\n",
    "        \"Untertitel\": subtitle,\n",
    "        \"VerlagId\": \"\",\n",
    "        \"Erscheinungsjahr\": publish_date,\n",
    "        \"SorteId\": \"\",\n",
    "        \"Kurzbeschreibung\": abstract if abstract else fake.paragraph(),\n",
    "        \"Preis\": str(price),\n",
    "        \"Auflage\": edition,\n",
    "        \"Sprache\": language\n",
    "    }\n",
    "\n",
    "    creator = creator if creator else fake.name()\n",
    "    val_person = {\n",
    "        \"Vorname\": creator.split(\" \")[0],\n",
    "        \"Name\": creator.split(\" \")[-1],\n",
    "        \"Email\": f\"{creator.split(' ')[0]}@{creator.split(' ')[-1]}.{fake.tld()}\",\n",
    "        \"Geburtsdatum\": fake.date_of_birth()\n",
    "    }\n",
    "\n",
    "    val_autor = {\n",
    "        \"PersonenId\": \"\",\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "\n",
    "    val_sorte = {\n",
    "        \"Name\": genre,\n",
    "        \"Beschreibung\": fake.paragraph()\n",
    "    }\n",
    "    \n",
    "    return val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOCK_STREAM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mgetaddrinfo\u001b[0;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0maddrlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_socket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetaddrinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m         \u001b[0maf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocktype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanonname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mgaierror\u001b[0m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-879bafa3a696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"text\"\u001b[0m \u001b[0;31m# \"still%20image\" \"moving%20image\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&sort=recordIdentifier&resourceType={typ}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    528\u001b[0m         }\n\u001b[1;32m    529\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             )\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 47 # 0\n",
    "typ = \"text\" # \"still%20image\" \"moving%20image\"\n",
    "\n",
    "r = requests.get(f\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&sort=recordIdentifier&resourceType={typ}\")\n",
    "obj = json.loads(r.text)\n",
    "\n",
    "total = obj.get(\"pagination\").get(\"numFound\")\n",
    "\n",
    "# obj.get(\"pagination\").get(\"numFound\") exists always\n",
    "for start_value in range( total // 250 + 1):\n",
    "    r = requests.get(f\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&start={start_value*250}&sort=recordIdentifier&resourceType={typ}\")\n",
    "    obj = json.loads(r.text)\n",
    "\n",
    "    for item in obj[\"items\"][\"mods\"]:\n",
    "        try:\n",
    "            if item[\"typeOfResource\"] == \"text\":\n",
    "                val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte = extractBook(item)\n",
    "                dbc.insert_book(val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte)\n",
    "            elif item[\"typeOfResource\"] == \"moving image\":\n",
    "                val_sorte, val_nichttextmedien, val_video = extractVideo(item)\n",
    "                dbc.insert_video(val_sorte, val_nichttextmedien, val_video)\n",
    "            else:\n",
    "                val_sorte, val_person, val_maler, val_nichttextmedien, val_bild = extractPicture(item)\n",
    "                dbc.insert_bild(val_sorte, val_person, val_maler, val_nichttextmedien, val_bild)\n",
    "        except Exception as e:\n",
    "            logging.error(e)\n",
    "    logging.info(f\"{(start_value+1)*250} of {total} ({((start_value+1)*250)/total} %)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing of extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&sort=recordIdentifier&resourceType=text\")\n",
    "# r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&sort=recordIdentifier\")\n",
    "# r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&resourceType=still%20image&limit=250&sort=recordIdentifier\")\n",
    "#r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=mona+lisa&resourceType=still%20image&limit=250&sort=recordIdentifier\")\n",
    "#r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&resourceType=still%20image&limit=250&sort=recordIdentifier\")\n",
    "# r = requests.get(\"https://api.lib.harvard.edu/v2/items.json?q=*&limit=250&resourceType=moving%20image&sort=recordIdentifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "status_code: 200\nlenght: 250\n"
    }
   ],
   "source": [
    "print(\"status_code: \" + str(r.status_code))\n",
    "obj = json.loads(r.text)\n",
    "print(\"lenght: \" + str(len(obj[\"items\"][\"mods\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ", {'Wort': 'History', 'Beschreibung': 'Particular glass art color look little manage. Finally red final boy common treat suffer.'}, {'Wort': 'New England', 'Beschreibung': 'Bill easy record reflect economic along. You walk president investment.'}, {'Wort': 'Christianity', 'Beschreibung': 'Almost pass general research. Share education else.'}]\n[{'Wort': 'Landscape architecture', 'Beschreibung': 'Pull pattern great by. Market with population but.'}]\n[{'Wort': 'Vocational guidance', 'Beschreibung': 'Better whom market. Fact read treatment yet scene site past. Home may personal light.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Individual phone when. Agreement phone wonder imagine page military. Behind state approach ball question by shoulder.'}]\n[{'Wort': 'Landscape architecture', 'Beschreibung': 'Represent deal own win southern politics live. Threat none represent across group appear concern threat.'}]\n[{'Wort': 'Iowa', 'Beschreibung': 'Society reflect soldier design class. Spend modern another.'}, {'Wort': 'Davenport', 'Beschreibung': 'Can spring middle. Not pressure culture if so full.'}, {'Wort': 'Civic improvement', 'Beschreibung': 'These within group fill guy. Some wall center hair. Add hope lot.'}]\n[{'Wort': 'New York (State)', 'Beschreibung': 'Work reach hospital space manage visit. Drop according pretty audience often safe environmental.'}, {'Wort': 'Environmental policy', 'Beschreibung': 'Own develop TV song property north offer. Eat a although contain field. Simple the soldier suddenly deep play.'}, {'Wort': 'Citizen participation', 'Beschreibung': 'Million positive let. Leader especially lay need number coach beyond.'}]\n[{'Wort': 'Gardening', 'Beschreibung': 'Kitchen doctor run term. Current move record finish health enough.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Statement perhaps themselves already information clear. Dark challenge spring decision. Change feeling hour authority force where discussion.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Strong certain national always memory despite outside.'}]\n[{'Wort': 'Landscape architecture', 'Beschreibung': 'Yet possible rate somebody anything. Lay since involve fish building professor maybe. Paper listen yeah dog town recognize clear.'}]\n[{'Wort': 'Gardening', 'Beschreibung': 'Maybe very mind amount. Natural catch entire or system. Stand be anyone rise law. Turn option we within staff first step.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Yard four laugh from hope American mean your. Family hope increase join growth participant.'}]\n[{'Wort': 'Gardening', 'Beschreibung': 'Scientist sound size nice newspaper other manager. Life since her poor worry individual. Some example especially give campaign movement everybody.'}, {'Wort': 'Competitions', 'Beschreibung': 'Appear wait statement last health hour. Church do color window yeah actually once truth. Present rate reveal executive and million. Sister card out ask.'}]\n[{'Wort': 'Shrubs', 'Beschreibung': 'Miss night candidate red suffer. Figure able example. Between mother trouble door turn.'}, {'Wort': 'Trees', 'Beschreibung': 'Public threat gas sign even. News describe whole former particular.'}, {'Wort': 'Climbing plants', 'Beschreibung': 'I east condition point Republican guess. Bit learn again act.'}]\n[{'Wort': 'Gardening', 'Beschreibung': 'Behind they however old natural little. Find arrive myself easy magazine.'}, {'Wort': 'Competitions', 'Beschreibung': 'Way after door his local vote anyone. Itself want after trouble yes dream. Daughter material prevent American.'}]\n[{'Wort': 'Landscape architecture', 'Beschreibung': 'Fear since top when. Father approach able single short. Fact social allow inside quickly style.'}]\n[{'Wort': 'Landscape architecture', 'Beschreibung': 'Effort forward art class report nature yes.'}]\n[{'Wort': 'Landscape architecture', 'Beschreibung': 'News natural year writer ago institution difference. Nearly law follow why entire. Benefit heart story might just hope.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Assume investment population bring health. Prepare tree much item method travel. Go season clear follow.'}]\n[{'Wort': 'Roadside improvement', 'Beschreibung': 'Action ago after yeah financial. Brother join same result star group manager herself.'}, {'Wort': 'Garden Club of America.', 'Beschreibung': 'Question lose modern society third region example. Defense we building modern. Use mention participant.'}, {'Wort': 'corporate', 'Beschreibung': 'Organization consider travel talk. Painting first dark truth continue dinner. Feel heavy may project throughout class away.'}, {'Wort': 'Billboard and Roadside Committee.', 'Beschreibung': 'Guess tell professor tend city. Door moment buy bring consider family develop. Least want different reveal ago middle within. Along rule step control occur want apply.'}]\n[{'Wort': 'Roadside improvement', 'Beschreibung': 'Radio choose gas unit actually country director week.'}, {'Wort': 'Forests and forestry', 'Beschreibung': 'Military gun understand again by fine ago. Control receive owner first result class. Laugh anything fight serve. Determine example sing bar.'}, {'Wort': 'New Hampshire', 'Beschreibung': 'Cover professor place apply wall pressure product focus. It a oil newspaper. Professional knowledge finally.'}]\n[{'Wort': 'Roadside improvement', 'Beschreibung': 'Radio choose gas unit actually country director week.'}, {'Wort': 'Forests and forestry', 'Beschreibung': 'Military gun understand again by fine ago. Control receive owner first result class. Laugh anything fight serve. Determine example sing bar.'}, {'Wort': 'New Hampshire', 'Beschreibung': 'Cover professor place apply wall pressure product focus. It a oil newspaper. Professional knowledge finally.'}]\n[{'Wort': 'Roadside improvement', 'Beschreibung': 'Capital describe role sometimes move way. Our generation to stand team.'}, {'Wort': 'Forests and forestry', 'Beschreibung': 'Stop agent performance. City especially mind wrong affect lose spring. Out story sea mention adult out guess.'}, {'Wort': 'New Hampshire', 'Beschreibung': 'Later ball international doctor fly himself. Model somebody grow statement plan part. Collection put network same phone situation Democrat.'}]\n[{'Wort': 'Georgia', 'Beschreibung': 'Million whatever drop almost manager forget nor. Challenge article on maybe dark work. Throw power view edge.'}, {'Wort': 'Roadside improvement', 'Beschreibung': 'Family easy plan industry store protect.'}]\n[{'Wort': 'Roadside rest areas', 'Beschreibung': 'Water experience only.'}, {'Wort': 'Massachusetts', 'Beschreibung': 'Scientist put PM include strategy wall action. Yeah beautiful safe grow. Newspaper hotel speak.'}]\n[{'Wort': 'n-us-nc', 'Beschreibung': 'Sure accept history notice. Heart market situation better sit event big new.'}, {'Wort': 'Bill-posting', 'Beschreibung': 'Follow trip method entire free win. How much do ground. Law kid his hot.'}, {'Wort': 'North Carolina', 'Beschreibung': 'Walk baby color decade message. Can tough worker involve last notice. Organization amount meet when.'}, {'Wort': 'Roads', 'Beschreibung': 'Partner good open effort. Environmental customer relationship off behind. Stock myself west. Nation billion agent scene arm argue style.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Well laugh project this career. Claim large wide easy cut agreement.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Attorney government condition. Low present time tree lead. Car serve PM.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Happen above game however even read recently message. Ten for team rather glass huge collection.'}]\n[{'Wort': 'Landscape architecture', 'Beschreibung': 'Kind light sound teach site value. Charge there themselves with.'}]\n[{'Wort': 'Massachusetts', 'Beschreibung': 'Visit including rather garden music property. Chance top gun age. How like wind by likely network goal.'}, {'Wort': 'Dedham', 'Beschreibung': 'Head president goal be agency back five letter. Everybody rather citizen.'}, {'Wort': 'Monuments', 'Beschreibung': 'Report deep treat it behavior commercial. Believe military product push exist. Far pressure day husband send subject about.'}]\n[{'Wort': 'Kansas City, Mo.', 'Beschreibung': 'Mean task maybe manage analysis apply traditional from.'}, {'Wort': 'Liberty Memorial.', 'Beschreibung': 'Drive within if someone visit according. Structure four expert professional company.'}, {'Wort': 'Liberty Memorial (Kansas City, Mo.)', 'Beschreibung': 'Himself feeling force return social feel street. Science current different place letter agree over money. Involve easy person six attack issue.'}, {'Wort': 'n-us-ks', 'Beschreibung': 'Heavy author nearly president down break fine social. Hear finally compare over focus. Fire successful art ask poor sing.'}, {'Wort': 'corporate', 'Beschreibung': 'Because behavior play fast care behind. But really but material civil. Continue blood pass wall class they difference.'}]\n[{'Wort': 'Open spaces', 'Beschreibung': 'Fast appear personal mention kid level. Product mission assume population owner shoulder series. Positive national see century.'}, {'Wort': 'California', 'Beschreibung': 'Clearly indicate town nearly professor similar research. Employee wide data difference land field sit.'}, {'Wort': 'San Mateo County', 'Beschreibung': 'Explain baby movement area may project police science. Increase style people institution investment wall.'}, {'Wort': 'Parks', 'Beschreibung': 'Guess hot her ground size. Alone every nearly produce interview those. Teach tell future six mention clear little.'}]\n[{'Wort': 'Scotland', 'Beschreibung': 'Wonder allow lawyer city at really kind. Near describe stage threat western. Total administration week picture behavior strong.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Better skin pull. Product specific number candidate civil happy before gas.'}]\n[{'Wort': 'Exhibitions', 'Beschreibung': 'Clear north cost thousand court politics particularly. Through develop claim owner star. Move decade thing for base discussion work.'}, {'Wort': 'Horticultural exhibitions', 'Beschreibung': 'Parent defense conference best. Want dream weight degree season camera message pass. Style lose help number performance.'}, {'Wort': 'Sculpture', 'Beschreibung': 'While significant police again stand. Military price trial situation the. Success together despite white miss our.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Admit say rather authority early huge interesting. Everyone door appear shake forward it.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Human general truth visit moment. Mrs national clear start TV structure. Worker impact stand hair technology.'}, {'Wort': 'History', 'Beschreibung': 'Various most note soon improve across. View leader worker total front because partner me. Claim travel TV player add Republican nation.'}]\n[{'Wort': 'Societies, etc', 'Beschreibung': 'Least once here south machine hour. Place concern left.'}, {'Wort': 'Gardening', 'Beschreibung': 'Admit family drive worker short everyone tend seem. Program race writer significant. Well difficult wonder sport similar.'}, {'Wort': 'Urban beautification', 'Beschreibung': 'Yard enter report body agent first. Network total effect night although yes.'}]\n[{'Wort': 'Urban beautification', 'Beschreibung': 'Skin central time behind. Price themselves myself cut speech traditional hold general.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Two protect cup charge benefit concern fine. Society new run modern news. Bring raise debate bank.'}]\n[{'Wort': 'Study and teaching', 'Beschreibung': 'Want second oil read eat occur. Key remain someone. Space beat economic.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Type throw believe financial might control.'}]\n[{'Wort': 'n-us-ok', 'Beschreibung': 'Indeed exactly throw remember tough. Trade glass case economic bank evidence. Whose PM Mr case they during clear.'}, {'Wort': 'Oklahoma', 'Beschreibung': 'Today main front interesting. Operation suggest area ball detail ever treat. Finally public within bit civil.'}, {'Wort': 'Landscape gardening', 'Beschreibung': 'Participant condition democratic in task. And then life second Mr. Little piece finally generation.'}]\n[{'Wort': 'Iowa', 'Beschreibung': 'Against of second many bed matter. Author important research result decision leader sense race. Law win technology notice analysis knowledge.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Owner left add thank population pick. Choice trip good somebody night until. Voice five candidate need level resource.'}]\n[]\n[{'Wort': 'Cooperative Extension Service.', 'Beschreibung': 'Card statement fish moment eat imagine guess history. Manager amount ability action why.'}, {'Wort': 'University of Massachusetts (Amherst campus).', 'Beschreibung': 'Impact need save especially memory. Rock tonight daughter memory bed ahead. Green leader live response drive health smile.'}, {'Wort': 'Landscape gardening', 'Beschreibung': 'Character health live go dream. They consumer onto wait wait. Job page without manager international trouble pick resource. It make because water money agency war.'}, {'Wort': 'corporate', 'Beschreibung': 'Letter again different agreement body fact. Yard push future however standard animal official.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Remember soon difficult eat last expert affect. Head their interest lawyer coach. Cut from nothing.'}]\n[{'Wort': 'Competitions', 'Beschreibung': 'Test cause recognize themselves opportunity. Everything sort wonder stop often between born. Baby structure feel early start social arrive.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Job themselves example. Section bar agreement collection learn. Activity enjoy that compare.'}]\n[{'Wort': 'Competitions', 'Beschreibung': 'High man away process other worker use grow.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Maintain art build them watch measure ever. Song property allow condition want move consider.'}]\n[]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Learn life risk paper people realize perform. Character agent whole opportunity develop serve while. Better act lead them.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Listen cause open main wait receive eye. Industry enter religious role.'}]\n[{'Wort': 'Study and teaching', 'Beschreibung': 'Sister relationship certainly begin fire. Town look certain a inside tend.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Together fly white time across play second. Page skin clearly other middle.'}]\n[{'Wort': 'Gardening', 'Beschreibung': 'While either window beat military. Political carry here tonight reflect threat technology.'}]\n[{'Wort': 'Gardens', 'Beschreibung': 'Until stand people happy see draw. Describe free political themselves worry among win. Standard herself detail effect likely gas.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Themselves future officer house hospital figure degree. Believe billion per school. Mean term both serious stock voice music.'}]\n[{'Wort': 'Roadside improvement', 'Beschreibung': 'Operation this hard particular would. Environment four arm yeah year business dog letter. What entire difference nearly.'}]\n[{'Wort': 'Roadside improvement', 'Beschreibung': 'Region environment much. Common piece truth military. Inside yes suddenly visit.'}, {'Wort': 'North Carolina', 'Beschreibung': 'Suggest dog tree these. Become include wind stock almost long lead.'}]\n[{'Wort': 'Roadside improvement', 'Beschreibung': 'News computer section look yourself might road. Service hundred thought same grow me system democratic. Through see then. Fine owner even ball she more environment skin.'}, {'Wort': 'California', 'Beschreibung': 'Media trip want discover nearly. Base serve safe official.'}]\n[{'Wort': 'Roadside improvement', 'Beschreibung': 'From need able. Enjoy realize give ball actually.'}, {'Wort': 'Oregon', 'Beschreibung': 'Job road particularly admit. Several lay happy they she risk.'}]\n[{'Wort': 'Landscape architecture', 'Beschreibung': 'Travel generation remain expert. Reduce from question line drive visit order. Case peace easy bill similar heavy film the.'}]\n[{'Wort': 'Homesites', 'Beschreibung': 'With huge myself better. Administration fear note back her record fire. Positive public beautiful notice.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Guy ago tough early deal music million nearly.'}]\n[{'Wort': 'Europe', 'Beschreibung': 'Less appear consumer realize six compare service. Pretty clear he economic probably training. Employee myself different technology little food summer type.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Into statement owner spend source she. Himself training give. Since seat old power subject budget be with.'}, {'Wort': 'Tours', 'Beschreibung': 'Lawyer gas much theory think continue car. Strategy debate responsibility data score. Something land ask ever vote evidence agreement.'}]\n[{'Wort': 'Catalogs', 'Beschreibung': 'Memory think reality decade part. Spring short education water contain size prepare mouth.'}, {'Wort': 'Toys', 'Beschreibung': 'According particular size open future onto left. Part writer prevent watch civil many. Us type somebody by.'}]\n[{'Wort': 'Interior decoration', 'Beschreibung': 'Plant his defense thousand. Artist field paper where middle draw feel.'}, {'Wort': 'Dwellings', 'Beschreibung': 'Message professor wonder teacher travel focus. Easy save major money gun consider alone brother.'}, {'Wort': 'conference', 'Beschreibung': 'Make man activity. Daughter that I.'}, {'Wort': 'Home Beautification Exposition (1st : 1921 : Boston, Mass.)', 'Beschreibung': 'Democrat item realize stand specific.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'Number hold represent site home fill. Its every agent reason democratic.'}]\n[{'Wort': 'Landscape gardening', 'Beschreibung': 'International experience social age accept open past. Because cultural resource special dream house somebody two. Entire decide never design choose next.'}, {'Wort': 'Study and teaching', 'Beschreibung': 'Develop clearly system. Ask rate hot phone age.'}]\n[{'Wort': 'Lowthorpe School of Landscape Architecture, Gardening, and Horticulture for Women.', 'Beschreibung': 'Important admit scene drop sense something report. Watch wonder soldier.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Plant likely industry itself will positive sit. Along address Republican believe pattern blood. Very section result contain for. Central whose happy benefit.'}, {'Wort': 'Study and teaching', 'Beschreibung': 'Notice start man thank. Understand morning young work contain could whatever. Generation management amount interview decide color. Attention say man thank.'}, {'Wort': 'corporate', 'Beschreibung': 'Tv nation contain choose. Away must unit available. Best billion step listen current.'}]\n[{'Wort': 'Lowthorpe School of Landscape Architecture, Gardening and Horticulture for Women.', 'Beschreibung': 'There claim and look yeah. Head unit TV manage practice right gun dark.'}, {'Wort': 'Professional education of women', 'Beschreibung': 'Civil number thank only. Pm gun through amount phone nor chair.'}, {'Wort': 'Massachusetts', 'Beschreibung': 'Simply staff call no material nearly could imagine. Ready station late different PM. Real lot understand board. Chair increase evening training.'}, {'Wort': 'Landscape architecture', 'Beschreibung': 'Benefit pattern something adult few statement their deep. Any between research smile until. Before bit against or.'}, {'Wort': 'corporate', 'Beschreibung': 'Sit cover reveal discussion talk. Want face pass key different before. Center several case end public series simple.'}, {'Wort': 'Study and teaching', 'Beschreibung': 'Cell number author still pay sort price forget. Young student current officer whatever suggest. Why inside head among box indicate.'}]\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-faa1edfe7419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"typeOfResource\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"text\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mval_schlagwort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_verlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_buch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_person\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_autor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_sorte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractBook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_schlagwort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m# dbc.insert_book(val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-1b3fde3811ea>\u001b[0m in \u001b[0;36mextractBook\u001b[0;34m(item)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;34m\"Strasse\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreet_address\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;34m\"Internetadresse\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;34m\"Beschreibung\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     }\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/faker/providers/lorem/__init__.py\u001b[0m in \u001b[0;36mparagraph\u001b[0;34m(self, nb_sentences, variable_nb_sentences, ext_word_list)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mnb_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandomize_nb_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         para = self.word_connector.join(self.sentences(\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mnb_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_word_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mext_word_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         ))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for num, item in enumerate(obj[\"items\"][\"mods\"]):\n",
    "    # print(num)\n",
    "    try:\n",
    "        if item[\"typeOfResource\"] == \"text\":\n",
    "            val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte = extractBook(item)\n",
    "            print(val_schlagwort)\n",
    "            # dbc.insert_book(val_schlagwort, val_verlag, val_buch, val_person, val_autor, val_sorte)\n",
    "        elif item[\"typeOfResource\"] == \"moving image\":\n",
    "            val_sorte, val_nichttextmedien, val_video = extractVideo(item)\n",
    "            # dbc.insert_video(val_sorte, val_nichttextmedien, val_video)\n",
    "        else:\n",
    "            val_sorte, val_person, val_maler, val_nichttextmedien, val_bild = extractPicture(item)\n",
    "            # dbc.insert_bild(val_sorte, val_person, val_maler, val_nichttextmedien, val_bild)\n",
    "    except Exception as e:\n",
    "        logging.error(traceback.print_exc())\n",
    "        logging.warning(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}